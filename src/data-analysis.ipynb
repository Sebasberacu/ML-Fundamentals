{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escuela de Ingeniería en Computación**\n",
    "\n",
    "**IC6200 - Inteligencia Artificial - Proyecto 1 - Machine Learning**\n",
    "\n",
    "**Estudiantes:**\n",
    "\n",
    "Gerald Núñez Chavarría, Sebastián Arroniz, Sebastián Bérmudez.\n",
    "\n",
    "**Profesor:**\n",
    "\n",
    "Kenneth Obando Rodríguez\n",
    "\n",
    "**Fecha de entrega:**\n",
    "\n",
    "26/04/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Entendimiento del Negocio**\n",
    "A continuación se presentan los objetivos del negocio y de la aplicación de la minería de datos en este proyecto de machine-learning, el cuál esta basado en el set de datos llamado \"Costa Rican Household Poverty Level Prediction\". \n",
    "### **1.1 Objetivo del Negocio**\n",
    "**Objetivo 1:** El principal objetivo del negocio es mejorar la precisión de la clasificación de hogares en niveles de pobreza utilizando modelos de machine learning, lo que permitirá a las agencias dirigir de manera más efectiva los recursos hacia quienes más lo necesitan.\n",
    "\n",
    "**Criterio de éxito:** El modelo predice el 90% de los casos de manera correcta. \n",
    "\n",
    "### **1.2 Objetivo de la Minería de Datos**\n",
    "\n",
    "**Objetivo 1:** Limpieza y preparación de datos: Preparar el conjunto de datos \"Costa Rican Household Poverty Level Prediction\" para su análisis y modelado, eliminando valores atípicos, tratando los valores faltantes y transformando variables según sea necesario. **Criterio de éxito:** Lograr un conjunto de datos limpio y completo listo para su análisis, con menos del 10% de datos faltantes y variables transformadas de manera adecuada. \n",
    "\n",
    "**Objetivo 2:** Análisis exploratorio de datos: Realizar un análisis exploratorio de los datos para comprender la distribución de las variables, identificar posibles relaciones y determinar la relevancia de las características para la predicción del nivel de pobreza del hogar. **Criterio de éxito:** Identificación de al menos X variables con alta correlación con el nivel de pobreza del hogar, y comprensión clara de la distribución de las características en el conjunto de datos.\n",
    "\n",
    "**Objetivo 3:** Seleccionar y entrenar un modelo de clasificación/regresión que brinde una mayor precisión para la predicción del nivel de pobreza. **Criterio de éxito:** El modelo predice al menos un X% y se valida mediante la técnica \"croos validation\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Entendimientos de los Datos**\n",
    "\n",
    "A continuación, se presenta de dónde se obtienen los datos y además, se describen los datos, se seleccionan variables importantes, se realizan ajustes y se verifica la calidad de los datos. \n",
    "\n",
    "### **2.1 Recolección Inicial de Datos.**\n",
    "\n",
    "Lo primero, es obtener el set de datos a utilizar, que es el de \"Costa Rican Household Poverty Level Prediction\", para esto, se descarga el archivo test.csv y train.csv que se encuentran en la página Kaggle en el siguiente link: https://www.kaggle.com/competitions/costa-rican-household-poverty-prediction/data. Los archivos se agregan en el directorio llamado `docs` y dentro del subdirectorio llamado `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read train data creating a pandas data frame\n",
    "df_train = pd.read_csv('../docs/data/train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar que la lectura de datos fue exitosa podemos llamar a la función `.head()` para mostrar las primeras cinco filas de cada set de datos (train y test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Descripción de los Datos**\n",
    "A partir de ahora se trabaja únicamente con los datos de entrenamiento. Debido a que estos son los que el modelo utiliza para aprender. Por esto se les debe analizar, describir, limpiar, modificar, etc... para obtener información valiosa para el modelo. Porqué si en el modelo **\"entra basura, sale basura\"**. \n",
    "\n",
    "En esta sección se muestra el tamaño, variables principales a utilizar, cantidad de registros y tipos de variables de los set de datos `train`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, obtengamos la cantidad de filas y de columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que son 9957 filas y 143 columnas. Podemos obtener más detalles utilzando la función `info()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las filas empiezan desde la 0 y llegan hasta la 9556. Las columnas empiezan desde Id y llegan hasta Target. Los tipos de datos son flotantes(8), enteros(130) y objetos(5).\n",
    "\n",
    "En el sito de Kaggle https://www.kaggle.com/competitions/costa-rican-household-poverty-prediction/data puede observar el nombre de las 143 columnas y su significado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 Exploración de los Datos**\n",
    "Para realizar la exploración de los datos, se van a seleccionar seis variables principales para poder describir y analizar un poco sobre los datos, las variables seleccionadas son: `rooms`, `escolari`, `hogar_total`, `age`, `overcrowding`, `Target`. \n",
    "\n",
    "El motivo de selección se debe a su potencial para poder clasificar el estado económico de los hogares. Por ejemplo, `rooms` podría estar relacionada con el tamaño de la vivienda y, por lo tanto, con las condiciones de vida, mientras que `escolari` (años de escolaridad) podría estar relacionada con el nivel educativo de los miembros del hogar, lo cual es un factor importante en el desarrollo y la movilidad económica. `hogar_total` (número total de personas en el hogar) y `age` (edad) también podrían proporcionar información importante sobre la composición y la demografía del hogar. `overcrowding` (sobrepoblación) es otra variable que podría indicar condiciones de vida inadecuadas si hay demasiadas personas por habitación en el hogar. Por último la variable objetivo `Target` que viene en el set de datos de entrenamiento y es una clasificación ordinal de cada fila con los siguientes valores:\n",
    "\n",
    "1 = pobreza extrema\n",
    "\n",
    "2 = pobreza moderada\n",
    "\n",
    "3 = hogares vulnerables\n",
    "\n",
    "4 = hogares no vulnerables. \n",
    "\n",
    "Ahora, apliquemos a estas variables la función `describe()` que permite obtener estadísticas de los datos en estas variables. Las estadíscticas que se obtienen son: Cuenta el número de observaciones no NA/nulas (`count`), el máximo de los valores del objeto (`max`), el mínimo de los valores del objeto(`min`), la media de los valores (`mean`) y la desviación estándar de las observaciones (`std`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the variables for the data frame and apply describe\n",
    "df_main_variables = df_train[['rooms', 'escolari', 'hogar_total', 'age', 'overcrowding', 'Target']]\n",
    "df_main_variables.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, analizando cada variable con el objetivo de ir obteniendo información valiosa de los datos:\n",
    "\n",
    "1. **rooms (número de habitaciones):**\n",
    "   - La media de 4.96 habitaciones sugiere que, en promedio, las viviendas tienen alrededor de 5 habitaciones.\n",
    "   - La desviación estándar relativamente baja de 1.47 indica que la cantidad de habitaciones tiende a variar poco entre las viviendas.\n",
    "   - La distribución muestra que el mínimo es 1 habitación y el máximo es 11 habitaciones, lo que sugiere una variedad en el tamaño de las viviendas dentro de la muestra.\n",
    "\n",
    "2. **escolari (años de escolaridad):**\n",
    "   - La media de 7.20 años de escolaridad indica que, en promedio, las personas en los hogares tienen poco más de 7 años de educación formal.\n",
    "   - La desviación estándar de 4.73 muestra una variabilidad relativamente alta en el nivel educativo de la muestra.\n",
    "   - La mínima de 0 años sugiere que hay personas sin educación formal en la muestra, mientras que la máxima de 21 años indica que algunas personas tienen educación universitaria o superior.\n",
    "\n",
    "3. **hogar_total (número total de personas en el hogar):**\n",
    "   - La media de aproximadamente 4 personas por hogar sugiere que, en promedio, los hogares tienen alrededor de 4 miembros.\n",
    "   - La desviación estándar de 1.77 indica cierta variabilidad en el tamaño de los hogares.\n",
    "   - La distribución muestra que el tamaño mínimo del hogar es 1 persona y el máximo es 13 personas, lo que sugiere una amplia gama de tamaños de hogar en la muestra.\n",
    "\n",
    "4. **age (edad):**\n",
    "   - La media de 34.30 años indica que la edad promedio en la muestra es de alrededor de 34 años.\n",
    "   - La desviación estándar de 21.61 muestra una variabilidad considerable en las edades de la muestra.\n",
    "   - La mínima de 0 años podría indicar la presencia de bebés o niños muy pequeños en algunos hogares, mientras que la máxima de 97 años sugiere la presencia de personas mayores.\n",
    "\n",
    "5. **overcrowding (sobrepoblación):**\n",
    "   - La media de 3. indica que, en promedio, hay alrededor de 1.6 personas por habitación en los hogares de la muestra.\n",
    "   - La desviación estándar de 0.82 sugiere cierta variabilidad en la sobrepoblación entre los hogares.\n",
    "   - La distribución muestra que el mínimo es 0.2 personas por habitación y el máximo es 6 personas por habitación, lo que indica una variedad en las condiciones de vida dentro de la muestra.\n",
    "\n",
    "6. **Target (variable objetivo):**\n",
    "   - La media de 3.30 indica que el nivel promedio de la variable objetivo es de alrededor de 3, lo que sugiere que la mayoría de los hogares se encuentran en la categoría de \"hogares vulnerables\".\n",
    "   - La desviación estándar de 1.01 indica que, en promedio, los valores de Target tienden a desviarse en aproximadamente 1 punto de la media.\n",
    "   - El valor mínimo de 1 y el valor máximo de 4 indican la presencia de hogares en todas las categorías de pobreza y vulnerabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a realizar un histograma para cada una de las variables, con el objetivo de visualizar graficamente lo ya analizado sobre la distribución de cada variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Selected variables\n",
    "main_variables = ['rooms', 'escolari', 'hogar_total', 'age', 'overcrowding', 'Target']\n",
    "\n",
    "# Generate histogram for each variable\n",
    "for variable in main_variables:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df_main_variables[variable], kde=True)\n",
    "    plt.title(f'Histograma de {variable}')\n",
    "    plt.xlabel(variable)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para obtener más información, podemos crear un diagrama de pares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a representation of relation between variables\n",
    "sns.pairplot(df_main_variables[main_variables])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden realizar apreciaciones importantes, cómo el hecho de que entre más escolaridad (`escolari`), menos sobre población por habitación (`overcrowding`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4 Calidad de los Datos**\n",
    "\n",
    "Por último es importante revisar la calidad de los datos. Lo primero que haremos, es verificar cuántos valores nulos existen, para esto, vamos a contar cuántos valores nulos existen por columna, para seguidamente mostrar todas las columnas que tienen valores nulos. Hay que tener en cuenta que la función `isnull()` únicamente cuenta los valores que son nulos indicados explicitamente o vacíos. Es decir, si se utiliza un código cómo por ejemplo `-1` para indicar que no se cuenta con el dato, entonces no nos dariamos cuenta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all null values for colums and show the colums with null values\n",
    "missing_values = df_train.isnull().sum()\n",
    "print(missing_values[missing_values != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que de las 143 columnas del set de datos de entrenamiento únicamente 5 son afectadas por datos nulos o vacíos. Sin embargo, en las primeras tres filas la cantidad de datos faltantes o nulos es mayor al 60% de las 9557 columnas del set de datos, lo cuál puede afectar significativamente el modelo al tomar en cuenta estas variables para realizar la clasificación. Se deben tomar desiciones respecto a estas variables en la sección 3. \n",
    "\n",
    "También, sería importante observar las variables que pandas identificó cómo tipo objeto y observar si tienen valores únicos o existe un desorden en los valores que no coincide con la definción de las variables y que puede afectar el entrenamiento del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns with 'object' type\n",
    "columnas_object = df_train.select_dtypes(include=['object']).columns\n",
    "print(columnas_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, observar los valores únicos no es necesario para las variables `Id` y `idhogar`, ya que van a tener valores variados.  Sin embargo, para las otras tres variables, que a continuación se anota su definición:\n",
    "\n",
    "`dependency`: Tasa de dependencia, calculada = (número de miembros del hogar menores de 19 años o mayores de 64)/(número de miembros del hogar entre 19 y 64 años)\n",
    "\n",
    "`edjefe`: años de educación del varón cabeza de familia, basado en la interacción de escolari (años de educación), cabeza de familia y sexo, sí=1 y no=0\n",
    "\n",
    "`edjefa`: años de educación del cabeza de familia femenino, basado en la interacción de escolari (años de educación), cabeza de familia y sexo, sí=1 y no=0\n",
    "\n",
    "Sería importante analizar que valores tienen para ver con que se va a entrenar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify unique values for object variabes\n",
    "print(df_train['dependency'].unique())\n",
    "print(df_train['edjefe'].unique())\n",
    "print(df_train['edjefa'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables tienen datos que no coinciden con la definición y van a ensuciar el modelo, también se debe sulocionar este problema en la sección 3. \n",
    "\n",
    "Por último, se mencionaba en la discusión publicada en la página de Kaggle, que hay algunos hogares que tienen un diferente Target, cuándo debería estar clasificados bajo uno mismo, comprobemos si es cierto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_targets = {} # Dictionary to store the target value for each household ID\n",
    "conflicting_households = [] # List to store the IDs of households with conflicting target values\n",
    "for row in df_train.iterrows():\n",
    "    id_hogar = row[1]['idhogar'] \n",
    "    target = row[1]['Target'] \n",
    "    if id_hogar in household_targets:\n",
    "        if household_targets[id_hogar] != target:\n",
    "            conflicting_households.append(id_hogar)\n",
    "    else:\n",
    "        household_targets[id_hogar] = target\n",
    "\n",
    "len(set(conflicting_households))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo se puede observar, hay 85 hogares que tienen conflicto de clasificación, esto es un problema que también se debe corregir en la sección 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Preparación de los Datos**\n",
    "\n",
    "En esta sección se presenta cómo se seleccionan, limpian, construyen y transforman los datos con el objetivo de obtener un set de datos de una mejor calidad y evitar que entre \"basura\" en el modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Selección de los Datos**\n",
    "\n",
    "Segundo, existen columnas que pueden ser eliminadas porqué realmente no aportan un valor al modelo para clasificar el nivel de pobreza. Otras pueden ser eliminadas porqué tienen un valor redundante (otra variable refleja casi lo mismo). Las primeras variables eliminadas serán:\n",
    "\n",
    "`r4h1`: Males younger than 12 years of age\n",
    "\n",
    "`r4h2`: Males 12 years of age and older\n",
    "\n",
    "`r4h3`: Total males in the household\n",
    "\n",
    "`r4m1`: Females younger than 12 years of age\n",
    "\n",
    "`r4m2`: Females 12 years of age and older\n",
    "\n",
    "`r4m3`: Total females in the household\n",
    "\n",
    "Esto porqué no nos aporta nada clasificar esto por género y ya contamos con las siguientes variables:\n",
    "\n",
    "`r4t1`: persons younger than 12 years of age\n",
    "\n",
    "`r4t2`: persons 12 years of age and older\n",
    "\n",
    "`r4t3`: Total persons in the household\n",
    "\n",
    "Otras variables que se pueden eliminar, son las que su valor es únicamente un cálculo al cuadrado, ya que no nos aporta nada más que obtener el valor de otra variable elevado al cuadrado. Estas son:\n",
    "\n",
    "`SQBescolari`: escolari squared\n",
    "\n",
    "`SQBage`: age squared\n",
    "\n",
    "`SQBhogar_total`: hogar_total squared\n",
    "\n",
    "`SQBedjefe`: edjefe squared\n",
    "\n",
    "`SQBhogar_nin`: hogar_nin squared\n",
    "\n",
    "`SQBovercrowding`: overcrowding squared\n",
    "\n",
    "`SQBdependency`: dependency squared\n",
    "\n",
    "`SQBmeaned`: square of the mean years of education of adults (>=18) in the household\n",
    "\n",
    "`agesq`: Age squared\n",
    "\n",
    "Esta son las variables que se consideran innecesarias y que no aportan al entrenamiento del modelo, sin embargo, no serán eliminadas de innmediato ya que sirven para corregir otras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Limpieza de los Datos**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero es corregir las columnas que tienen valores nulos. Este cálculo ya se hizo, pero refresquemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all null values for colums and show the colums with null values\n",
    "missing_values = df_train.isnull().sum()\n",
    "print(missing_values[missing_values != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que las variables involucradas son: `v2a1`, `v18q1`, `rez_esc`, `meaneduc` y `SQBmeaned`. \n",
    "\n",
    "mpecemos con `meaneduc` (`SQBmeaneduc` será eliminada luego, por lo tanto no necesita arreglar los valores), que mide el promedio de educación de los adultos mayores a 18 años en ese hogar. Entonces, observemos cuál es el `idhogar` dónde tenemos un `meaneduc` nulo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all hogar id's where meaneduc is equal to NaN (null)\n",
    "df_train[df_train['meaneduc'].isnull()][['idhogar', 'age', 'escolari', 'meaneduc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del resultado podemos observar si hay personas mayores de 18 años en dónde los campos de `meaneduc` son igual a NaN. Además, que realmente solo son 3 hogares que tienen este defecto (hay repetidos). Veamos si viven más personas en estos hogares o únicamente las 5 que se muestran en los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train[df_train['idhogar'] == df_train.iloc[1291]['idhogar']]))\n",
    "print(len(df_train[df_train['idhogar'] == df_train.iloc[1840]['idhogar']]))\n",
    "print(len(df_train[df_train['idhogar'] == df_train.iloc[2049]['idhogar']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es favorable, porqué demuestra que solo estas personas viven en esos hogares lo que facilita rellenar los datos nulos de `meaneduc`. Para el primer hogar (fila 1291) simplemente es sustituir el valor nulo de `meaneduc` por el valor de `escolari` ya que no vive nadie más por lo tanto ese es el promedio. Para el segundo caso y tercer caso, se toman los valores de escolari de ambas filas y se dividen entre 2, para obtener el promedio de `meaneduc` y rellenar esos valores nulos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First household\n",
    "escolari_value = df_train.loc[1291, 'escolari']\n",
    "\n",
    "df_train.loc[1291, 'meaneduc'] = escolari_value\n",
    "\n",
    "# Second household\n",
    "escolari_value1 = df_train.loc[1840, 'escolari']\n",
    "escolari_value2 = df_train.loc[1841, 'escolari']\n",
    "meaneduc = (escolari_value1 + escolari_value2) / 2\n",
    "\n",
    "df_train.loc[1840, 'meaneduc'] = meaneduc\n",
    "df_train.loc[1841, 'meaneduc'] = meaneduc\n",
    "\n",
    "\n",
    "# Third household\n",
    "escolari_value1 = df_train.loc[2049, 'escolari']\n",
    "escolari_value2 = df_train.loc[2050, 'escolari']\n",
    "meaneduc = (escolari_value1 + escolari_value2) / 2\n",
    "\n",
    "df_train.loc[2049, 'meaneduc'] = meaneduc\n",
    "df_train.loc[2050, 'meaneduc'] = meaneduc\n",
    "\n",
    "# Now we are filled this NaN values. \n",
    "print(df_train.loc[[1291, 1840, 1841, 2049, 2050]][['idhogar', 'meaneduc']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora toca arreglar una variable muy importante cómo lo es `v2a1` que hace referencia al pago mensual renta por mes y tiene 6860 valores pérdidos. No obstante, hay otras variables que hacen referencia al tipo de vivienda, y nos inidican por ejemplo si es casa propia o un lugar precario, entre otros. Demos un vistazo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rent = df_train[df_train['v2a1'].isnull()]\n",
    "print(\"Casa propia: \", no_rent[no_rent['tipovivi1']==1]['Id'].count())\n",
    "print(\"Es propietario de su casa pagando cuotas: \", no_rent[no_rent['tipovivi2']==1]['Id'].count())\n",
    "print(\"Alquila: \", no_rent[no_rent['tipovivi3']==1]['Id'].count())\n",
    "print(\"Precario: \", no_rent[no_rent['tipovivi4']==1]['Id'].count())\n",
    "print(\"Other: \", no_rent[no_rent['tipovivi5']==1]['Id'].count())\n",
    "print(\"Total \", 6860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, la mayoría son propietarios de sus casas, sólo unos pocos tienen situaciones extrañas. Probablemente podemos suponer que no pagan alquiler, y poner 0 en estos casos, para no lidiar con los valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v2a1'] = df_train['v2a1'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuánto al número de tabletas que posee el hogar (`v18q1`) que tiene 7342 conlumnas nulas, podemos utilizar la variables `v18q` que indica el si el hogar posee o no tabletas, podemos inspeccionar a ver si los valores nulos a la vez coinciden con qué el hogar no tiene tabletas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifiy if the null values of v18q1 is a consecuence of a 0 (does not have tablets) in v18q\n",
    "nan_tablet = df_train[df_train['v18q1'].isnull()]\n",
    "nan_tablet[nan_tablet['v18q']==0]['Id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente, quiere decir que cuándo `v18q1` es nulo es porqué no hay tabletas en el hogar. Entonces podemos cambiar todos los nulos por 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all nan values for v18q1 with zeros.\n",
    "df_train['v18q1'] = df_train['v18q1'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la última variable a la que le debemos limpiar sus valores nulos es `rez_esc` que indica la cantidad de años de retraso escolar que lleva una persona. Esta tiene 7928 valores nulos. Intentemos ver primero que todo si sigue algún patrón:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc'] = df_train['rez_esc'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Transformaciones en los Datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables categoricas `dependency`, `edjefe` y `edjefa` tienen valores que pueden confundir al modelo, observemos nuevamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify unique values for object variabes\n",
    "print(df_train['dependency'].unique())\n",
    "print(df_train['edjefe'].unique())\n",
    "print(df_train['edjefa'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De momento corran este código luego expico bien qué es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8584\\1288059012.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_main_variables['dependency'] = np.sqrt(dataset['SQBdependency'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_train['dependency'] = np.sqrt(df_train['SQBdependency'])\n",
    "\n",
    "conditions = [\n",
    "    (df_train['edjefe']=='no') & (df_train['edjefa']=='no'), #both no\n",
    "    (df_train['edjefe']=='yes') & (df_train['edjefa']=='no'), # yes and no\n",
    "    (df_train['edjefe']=='no') & (df_train['edjefa']=='yes'), #no and yes \n",
    "    (df_train['edjefe']!='no') & (df_train['edjefe']!='yes') & (df_train['edjefa']=='no'), # number and no\n",
    "    (df_train['edjefe']=='no') & (df_train['edjefa']!='no') # no and number\n",
    "    ]\n",
    "\n",
    "choices = [0, 1, 1, df_train['edjefe'], df_train['edjefa']]\n",
    "df_train['edjefx']=np.select(conditions, choices)\n",
    "df_train['edjefx']=df_train['edjefx'].astype(int)\n",
    "df_train.drop(['edjefe', 'edjefa'], axis=1, inplace=True)\n",
    "\n",
    "for i in set(conflicting_households):\n",
    "    household_subset = df_train[df_train['idhogar']==i][['idhogar', 'parentesco1', 'Target']]\n",
    "    target = household_subset[household_subset['parentesco1']==1]['Target'].tolist()[0]\n",
    "    for row in household_subset.iterrows():\n",
    "        idx = row[0]\n",
    "        if row[1]['parentesco1'] != 1:\n",
    "            df_train.at[idx, 'Target'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Modelado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la parte del modelado, lo primero es cargar el set de datos de prueba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read train and test data creating a pandas data frame\n",
    "df_test = pd.read_csv('../docs/data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, creamos esta función para realizar todas las operaciones para seleccionar, limpiar, agregar y modificar datos. A esta función le llamaremos `clean_data` y es para limpiar el set de datos de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dataset):\n",
    "    # Fix meaneduc nan values\n",
    "    escolari_value = dataset.loc[1291, 'escolari']\n",
    "    dataset.loc[1291, 'meaneduc'] = escolari_value\n",
    "\n",
    "    escolari_value1 = dataset.loc[1840, 'escolari']\n",
    "    escolari_value2 = dataset.loc[1841, 'escolari']\n",
    "    meaneduc = (escolari_value1 + escolari_value2) / 2\n",
    "    dataset.loc[1840, 'meaneduc'] = meaneduc\n",
    "    dataset.loc[1841, 'meaneduc'] = meaneduc\n",
    "\n",
    "    escolari_value1 = dataset.loc[2049, 'escolari']\n",
    "    escolari_value2 = dataset.loc[2050, 'escolari']\n",
    "    meaneduc = (escolari_value1 + escolari_value2) / 2\n",
    "    dataset.loc[2049, 'meaneduc'] = meaneduc\n",
    "    dataset.loc[2050, 'meaneduc'] = meaneduc\n",
    "    \n",
    "    # Fill with zeros v2a1 nan values. \n",
    "    dataset['v2a1'] = dataset['v2a1'].fillna(0)\n",
    "    \n",
    "    # Fill with zeros v18q1 nan values.\n",
    "    dataset['v18q1'] = dataset['v18q1'].fillna(0)\n",
    "    \n",
    "    # Fill with zeros rez_esc nan values\n",
    "    dataset['rez_esc'] = dataset['rez_esc'].fillna(0)\n",
    "    \n",
    "    df_main_variables['dependency'] = np.sqrt(dataset['SQBdependency'])\n",
    "\n",
    "    conditions = [\n",
    "        (dataset['edjefe']=='no') & (dataset['edjefa']=='no'), #both no\n",
    "        (dataset['edjefe']=='yes') & (dataset['edjefa']=='no'), # yes and no\n",
    "        (dataset['edjefe']=='no') & (dataset['edjefa']=='yes'), #no and yes \n",
    "        (dataset['edjefe']!='no') & (dataset['edjefe']!='yes') & (dataset['edjefa']=='no'), # number and no\n",
    "        (dataset['edjefe']=='no') & (dataset['edjefa']!='no') # no and number\n",
    "        ]\n",
    "\n",
    "    choices = [0, 1, 1, dataset['edjefe'], dataset['edjefa']]\n",
    "    dataset['edjefx']=np.select(conditions, choices)\n",
    "    dataset['edjefx']=dataset['edjefx'].astype(int)\n",
    "    dataset.drop(['edjefe', 'edjefa'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Criterios de Selección**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Conclusiones**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
